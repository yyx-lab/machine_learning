# 1. 第一章 绪论

## 1.1 基本术语

在计算机上从数据中产生**模型model/学习器learner**的算法，即**学习算法learning algorithm**

+ **数据集data set**
+ **样本sample/示例instance**
+ **特征feature/属性attribute**
+ **属性值attribute value**
+ **样本空间sample space/属性空间attribute space**
+ **特征向量feature vector**: 把一个示例/样本 称为 一个特征向量



数学描述：

一般地，令$D=\{x_1, x_2, ..., x_m\}$表示包含$m$个**示例**的**数据集**，

每个示例由$d$个**属性**描述，

则

每个示例写做$x_i = (x_{i1}; x_{i2}; ...;x_{id})$，是$d$维**样本空间**$\chi$中的一个向量，$x_i\in\chi$，

其中$x_{ij}$是$x_i$在第$j$个属性上的取值，$d$称为样本$x_i$的**维数**。



+ **学习learning/训练training**： 从数据中学得模型的过程
+ **训练样本training sample**
+ **训练数据training data**: 训练过程中使用的数据
+ **训练集training set**
+ **假设hypothesis**——**真相/真实ground-truth**



+ **标记label**：描述示例/样本结果的信息
+ **样例example**：拥有了标记信息的示例/样本
+ **输出空间/标记空间label space**



数学描述：

$$(x_i, y_i)$$表示第$$i$$个**样例**,

其中$$y_i\in\gamma$$是示例$$x_i$$的**标记**，

$$\gamma$$是所有标记的集合，也称**标记空间/输出空间**。



+ 预测的（输出空间）是离散值——此类学习任务称为**分类classification**

  ($$\gamma$$为一集合)

  + 二分类binary classification	正类positive class		反类/负类negative class
  + 多分类multi-class classification

+ 预测的（输出空间）是连续值——此类学习任务称为**回归regression**

  （$$\gamma=\mathbb{R}$$）



数学描述：

一般地，**预测任务**是希望通过对训练集$$\{(x_1, y_1), (x_2, y_2), ...,(x_m, y_m)\}$$进行学习，建立一个从输入空间到输出空间的映射。



+ 训练数据有标记信息的学习任务为：**监督学习supervised learning**

  （分类和回归都是监督学习）

+ 训练数据没有标记信息的学习任务为：**无监督学习unsupervised learning**

## 1.2 假设空间

+ 学习的过程可以看做是一个在所有**假设hypothesis**组成的空间中进行搜索的过程，搜索目标是找到与训练集“匹配”的假设，即能够将训练集中的瓜判断正确的假设。

+ **版本空间**：可能有多个假设与训练集一致，存在着一个鳄鱼训练集一致的“假设集合”

## 1.3 归纳偏好

+ 归纳偏好：机器学习在学习过程中对某种类型假设的偏好
+ 奥卡姆剃刀(Occam's razor)原则：若有多个假设与观察一致，则选择最简单的那个
+ NFL（没有免费的午餐定理）定理：无论学习算法a多聪明，算法b多笨拙，他们的期望性能竟相同。前提：所有“问题”出现的机会相同、或者所有问题同等重要。
+ 脱离具体问题，空泛的谈论“什么学习算法更好”毫无意义，要谈论算法的相对优劣，必须要针对具体的学习问题。
+ 学习算法自身的归纳偏好与问题是否相配，往往会起到决定性的作用。

# 2. 第二章 模型评估与选择

待补。。

## 2.1 经验误差与过拟合

- 误差(error)：学习器的实际预测输出与样本之间的真实输出之间的差异
- 过拟合：学习器把训练样本自身的一些特点当做了所有潜在样本都会具有的一般性质，会导致泛化性能下降

## 2.2评估方法

测试集(testing set)：测试学习器对新样本的判别能力

测试误差：(testing error)：以测试集上的“测试误差”作为泛化误差的近似

注：测试集应该尽可能与训练集互斥，即测试样本不在训练集中出现、未在训练过程中使用过

数据集划分：通过对数据集D进行适当处理，从中产出训练集S和测试集T。

### 2.2.1留出法

- 概念：直接将数据集D划分为两个互斥的集合，其中一个集合作为训练集S，另一个作为测试集T，在S上训练出模型后，用T来评估测试误差，作为对泛化误差的估计。
- 注：训练/测试集的划分要尽可能保持数据分布的一致性，避免引入额外偏差对结果造成影响，eg.在分类任务重至少要保持样本类别比例相似（分层采样：保留类别比列的采样方式）。
- 注：单次使用留出法往往不够稳定可靠，在使用留出法时，一般要采用若干次所及划分、重复进行实验评估后取平均值作为留出法的估计结果。
- 缺点：划分数据集时，测试集小时，评估结果的方差较大；训练集小时，评估结果的偏差较大
- 解决方案：一般是将大约2/3~4/5的样本用于训练，剩余样本用于测试

### 2.2.2交叉验证法

- 概念：先将数据集D划分为k个大小相似的互斥子集，每个子集Di都是通过分层采样得到，然后每次用k-1个子集的病机作为训练集，余下的那个子集作为测试集，从而可以获得k组训练/测试集，进行k次训练和测试，最终返回k个测试结果的均值。

- k折交叉验证通常要随机使用不同的划分重复p次，最终的评估结果是这p次k折交叉验证结果的均值，eg.10次10折交叉验证。
- 特例：留一法，数据集D中包含m个样本，若令k = m，使得被上级评估的模型与期望评估的用D训练处的模型很相似，缺陷：数据集较大时难以计算

### 2.2.3自助法

- 概念：直接以自助采样法为基础，给定包含m个样本的数据集D，对它进行采样产生数据集D'：每次随机从D中随机调训啊一个样本，将其拷贝放入D'，然后再将该样本放回初始数据集中（相当于采样之后又重新放回）。
- 于是可将D'用于训练集，D/D'用作测试集
- 包外估计：这样实际评估的模型与期望评估的模型都使用m个训练样本，仍有数据总量月1/3的、没在训练集中出现过的样本用于测试。
- 优点：1.减少训练样本不同造成的影响，比较高效的进行实验估计2.在数据集较小、难以有效划分训练/测试数据集时很有用3.从初始训练集中产生多个不同的训练集，对集成学习等方法有很大好处。
- 缺点：产生的数据集改变了原始数据集的分布，会引入估计偏差

### 2.2.4调参与最终模型

- 参数调节：在进行模型评估与选择时，除了要对适用学习的算法进行选择，还需对算法参数进行设定
- 注：学习算法的很多参数是在实数范围内取值，因此，对每种参数都训练处模型来是不可能的，常用的做法是对每个参数选定一个**范围和变化步长**，eg.在[0,0.2]范围内以0.05为步长，则实际要评估的候选参数值有5个，最终在浙5 个候选值中产生选定值。
- 重新训练模型：在模型选择完成后，学习算法和参数已经选定，此时应该用数据集D重新训练模型，这才是最终提交给用户的模型
- 测试数据：学得模型在实际使用中遇到的数据
- 经验集：模型评估与选择中用于评估测试的数据集



